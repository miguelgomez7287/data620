{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8cb06cd-74e7-46ab-9bec-6ca6e1f2df09",
   "metadata": {},
   "source": [
    "\n",
    "# Repeat Themes in Kanye West’s Lyrics: Wealth, Religion, and Relationships\n",
    "\n",
    "Using the Kaggle dataset: > `convolutionalnn/kanye-west-lyrics-dataset`\n",
    "\n",
    "This script does the following:\n",
    "\n",
    "1. Data download and loading (via `kagglehub`)\n",
    "2. Text preprocessing (tokenization, stopword removal, lemmatization)\n",
    "3. Word frequency analysis\n",
    "4. Sentiment analysis (VADER)\n",
    "5. Word co-occurrence network (NetworkX)\n",
    "6. Topic modeling (LDA)\n",
    "7. Word clouds (overall and per album)\n",
    "8. Theme keyword analysis (wealth, religion, relationships)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff66c13",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Setup and Library Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc57941e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install kagglehub\n",
    "#!pip install pandas matplotlib seaborn nltk networkx gensim wordcloud\n",
    "#!pip install wordcloud\n",
    "\n",
    "  \n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "import string\n",
    "import networkx as nx\n",
    "import csv\n",
    "\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "import kagglehub\n",
    "import re\n",
    "\n",
    "from collections import Counter\n",
    "import itertools\n",
    "\n",
    "\n",
    "# Make plots a bit nicer\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 5)\n",
    "\n",
    "# Download NLTK resources (safe to run multiple times)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('vader_lexicon', quiet=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76a80d3",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Download the Kanye West Lyrics Dataset from Kaggle.\n",
    "\n",
    "I used `kagglehub` to automatically download the latest version of the dataset from Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06b383e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset directory: C:\\Users\\hotga\\.cache\\kagglehub\\datasets\\convolutionalnn\\kanye-west-lyrics-dataset\\versions\\1\n",
      "Files found in dataset directory: ['Kanye West Lyrics.txt']\n",
      "Using data file: C:\\Users\\hotga\\.cache\\kagglehub\\datasets\\convolutionalnn\\kanye-west-lyrics-dataset\\versions\\1\\Kanye West Lyrics.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Download latest version of the dataset from Kaggle\n",
    "dataset_dir = kagglehub.dataset_download(\"convolutionalnn/kanye-west-lyrics-dataset\")\n",
    "print(\"Dataset directory:\", dataset_dir)\n",
    "\n",
    "# Inspect files in the dataset directory\n",
    "files = os.listdir(dataset_dir)\n",
    "print(\"Files found in dataset directory:\", files)\n",
    "\n",
    "# Automatically pick the first .txt or .csv file\n",
    "data_file = None\n",
    "for f in files:\n",
    "    if f.lower().endswith(\".txt\") or f.lower().endswith(\".csv\"):\n",
    "        data_file = os.path.join(dataset_dir, f)\n",
    "        break\n",
    "\n",
    "if data_file is None:\n",
    "    raise FileNotFoundError(\"No .txt or .csv file found in the dataset directory. Check Kaggle dataset contents.\")\n",
    "\n",
    "print(\"Using data file:\", data_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e2d28c",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## 3. Load and Inspect the Dataset\n",
    "\n",
    "The dataset file may be in `.txt` or `.csv` format.  \n",
    "I will try to read it as a regular CSV first, and if that fails, we try tab-separated text.\n",
    "\n",
    "Also, I normalized column names to lowercase and ensure that there is a `lyrics` column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "761b4e5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw text from: C:\\Users\\hotga\\.cache\\kagglehub\\datasets\\convolutionalnn\\kanye-west-lyrics-dataset\\versions\\1\\Kanye West Lyrics.txt\n",
      "Total text blocks (approx songs/verses): 944\n",
      "DataFrame shape: (944, 1)\n",
      "Columns: ['lyrics']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>﻿[Chorus]\\nSing every hour (Every hour, 'til t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Verse]\\nSing 'til the power of the Lord comes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Chorus]\\nSing every hour (Every hour, 'til th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Bridge]\\nSing 'til the power of the Lord come...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Chorus]\\nSing every hour (Every hour, 'til th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              lyrics\n",
       "0  ﻿[Chorus]\\nSing every hour (Every hour, 'til t...\n",
       "1  [Verse]\\nSing 'til the power of the Lord comes...\n",
       "2  [Chorus]\\nSing every hour (Every hour, 'til th...\n",
       "3  [Bridge]\\nSing 'til the power of the Lord come...\n",
       "4  [Chorus]\\nSing every hour (Every hour, 'til th..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_dataset(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load the Kanye West lyrics dataset from the Kaggle text file.\n",
    "\n",
    "    The original dataset is a single .txt file, not a structured CSV table.\n",
    "\n",
    "    1. Read the entire file as raw text.\n",
    "    2. Split the text into blocks separated by blank lines.\n",
    "       (Each block is treated as one song/verse document.)\n",
    "    3. Return a DataFrame with a single column: 'lyrics'.\n",
    "    \"\"\"\n",
    "    print(\"Loading raw text from:\", file_path)\n",
    "\n",
    "    # Read the file as plain text\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    # Split on double newlines -> each block ~ one song/verse\n",
    "    blocks = [b.strip() for b in text.split(\"\\n\\n\") if b.strip()]\n",
    "\n",
    "    print(f\"Total text blocks (approx songs/verses): {len(blocks)}\")\n",
    "\n",
    "    df = pd.DataFrame({\"lyrics\": blocks})\n",
    "\n",
    "    print(\"DataFrame shape:\", df.shape)\n",
    "    print(\"Columns:\", df.columns.tolist())\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = load_dataset(data_file)\n",
    "\n",
    "# Quick peek\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070eacbb",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Text Preprocessing: Tokenization, Stopwords, Lemmatization\n",
    "\n",
    "To prepare the lyrics for analysis:\n",
    "\n",
    "- Convert text to lowercase  \n",
    "- Remove punctuation  \n",
    "- Tokenize into words  \n",
    "- Remove English stopwords ('the', 'and')  \n",
    "- Lemmatize words to their base form ('running' → 'run')  \n",
    "\n",
    "This results in a normalized `tokens` column I can use for all analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e519a629",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def clean_text(text: str):\n",
    "    # ----------------------------------------------\n",
    "    # 1. Remove anything inside square brackets\n",
    "    #    Examples removed:\n",
    "    #    [Chorus], [Verse 2: Kanye West], [Outro: Kanye & Choir]\n",
    "    # ----------------------------------------------\n",
    "    text = re.sub(r\"\\[.*?\\]\", \"\", text)\n",
    "\n",
    "    # 2. Lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # 3. Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # 4. Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # 5. Remove stopwords and short tokens\n",
    "    tokens = [t for t in tokens if t not in stop_words and len(t) > 2]\n",
    "\n",
    "    # 6. Lemmatize words to base form\n",
    "    tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
    "\n",
    "    return tokens\n",
    "\n",
    "df[\"tokens\"] = df[\"lyrics\"].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43b40a5",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Word Frequency Analysis\n",
    "\n",
    "Examine the most frequently used words across Kanye's lyrics.\n",
    "\n",
    "This helps me see which concepts are dominant in his vocabulary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064fa94b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def analyze_word_frequencies(df: pd.DataFrame, top_n: int = 30):\n",
    "    all_tokens = [token for sublist in df[\"tokens\"] for token in sublist]\n",
    "    freq = Counter(all_tokens)\n",
    "    common = freq.most_common(top_n)\n",
    "    \n",
    "    print(f\"Top {top_n} most common words:\")\n",
    "    for word, count in common:\n",
    "        print(f\"{word}: {count}\")\n",
    "    \n",
    "    words, counts = zip(*common)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=list(counts), y=list(words))\n",
    "    plt.title(f\"Top {top_n} Words in Kanye West Lyrics\")\n",
    "    plt.xlabel(\"Count\")\n",
    "    plt.ylabel(\"Word\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "analyze_word_frequencies(df, top_n=30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ad1b4e",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Sentiment Analysis (VADER)\n",
    "\n",
    "NLTK's VADER sentiment analyzer to measure:\n",
    "\n",
    "- Negative (`neg`)  \n",
    "- Neutral (`neu`)  \n",
    "- Positive (`pos`)  \n",
    "- Overall compound score (`compound`)  \n",
    "\n",
    "for each lyrics entry. This gives me a sense of the emotional tone of Kanye's songs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a70122",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_sentiment_analysis(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    sentiment_dicts = df[\"lyrics\"].apply(sia.polarity_scores)\n",
    "    sentiment_df = pd.json_normalize(sentiment_dicts)\n",
    "    df_sent = pd.concat([df.reset_index(drop=True), sentiment_df], axis=1)\n",
    "    \n",
    "    print(\"Example sentiment scores:\")\n",
    "    display(df_sent[[\"lyrics\", \"neg\", \"neu\", \"pos\", \"compound\"]].head(3))\n",
    "    \n",
    "    # Plot distribution of compound scores\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.histplot(df_sent[\"compound\"], bins=50, kde=True)\n",
    "    plt.title(\"Distribution of Compound Sentiment Scores\")\n",
    "    plt.xlabel(\"Compound Score\")\n",
    "    plt.ylabel(\"Number of Songs\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # If album info exists, show sentiment by album\n",
    "    if \"album\" in df_sent.columns:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.boxplot(data=df_sent, x=\"album\", y=\"compound\")\n",
    "        plt.xticks(rotation=45, ha=\"right\")\n",
    "        plt.title(\"Sentiment (Compound) by Album\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return df_sent\n",
    "\n",
    "df = run_sentiment_analysis(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90551d67",
   "metadata": {},
   "source": [
    "\n",
    "## 7. Word Cloud (Global Only)\n",
    "\n",
    "The dataset does not include album info, so I generated **only a global word cloud** using the cleaned tokens (with bracketed sections like [Chorus] removed).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4766c4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_global_wordcloud(df: pd.DataFrame):\n",
    "    # Build a single big string from cleaned tokens\n",
    "    all_tokens = [token for sublist in df[\"tokens\"] for token in sublist]\n",
    "    all_text = \" \".join(all_tokens)\n",
    "\n",
    "    wc = WordCloud(\n",
    "        width=1200,\n",
    "        height=800,\n",
    "        background_color=\"white\"\n",
    "    ).generate(all_text)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Kanye West Lyrics – Global WordCloud (Cleaned)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "generate_global_wordcloud(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34e151d",
   "metadata": {},
   "source": [
    "\n",
    "## 8. Theme Keyword Analysis: Wealth, Religion, Relationships\n",
    "\n",
    "To directly test the hypothesis:\n",
    "\n",
    "1. Define keyword lists for each theme.  \n",
    "2. Count how many times theme-related words appear in each song.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351f0218",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Theme keyword lists\n",
    "THEMES = {\n",
    "    \"wealth\": [\n",
    "    \"money\", \"cash\", \"gold\", \"rich\", \"bank\", \"wealth\", \"luxury\", \"designer\",\n",
    "    \"ice\", \"diamond\", \"diamonds\", \"fame\", \"famous\", \"chain\", \"chains\",\n",
    "    \"rollie\", \"roli\", \"rolie\", \"watch\", \"rolls\", \"phantom\", \"benz\", \"bugatti\",\n",
    "    \"dollars\", \"stacks\", \"band\", \"bands\", \"grand\", \"credit\", \"irs\", \"income\",\n",
    "    \"tax\", \"taxes\", \"tithe\",\n",
    "    \"yacht\", \"mansion\", \"jet\", \"private\",\n",
    "    \"lavish\", \"ballin\", \"stunt\", \"flex\", \"drip\"\n",
    "],\n",
    "    \"religion\": [\n",
    "    \"god\", \"jesus\", \"lord\", \"heaven\", \"hell\", \"holy\", \"spirit\", \"faith\",\n",
    "    \"pray\", \"prayer\", \"worship\", \"praise\", \"hallelujah\", \"gospel\", \"choir\",\n",
    "    \"church\", \"amen\", \"blessing\", \"blessings\", \"salvation\", \"grace\",\n",
    "    \"forgive\", \"forgiveness\", \"sin\", \"sins\", \"scripture\",\n",
    "    \"angel\", \"angels\", \"devil\", \"demons\",\n",
    "    \"abraham\", \"noah\", \"judas\",\n",
    "    \"saint\", \"ultrabeam\", \"hallelujah\", \"christ\", \"jesus\", \"christ-like\"\n",
    "],\n",
    "    \"relationships\": [\n",
    "    \"love\", \"lover\", \"loving\", \"heart\", \"kiss\", \"girl\", \"girls\", \"woman\",\n",
    "    \"women\", \"girlfriend\", \"boy\", \"relationship\", \"wife\", \"husband\", \"baby\",\n",
    "    \"romance\", \"together\", \"family\", \"mama\", \"dad\", \"daddy\", \"daughter\",\n",
    "    \"son\", \"brother\", \"sister\", \"cousin\",\n",
    "    \"touch\", \"feel\", \"feelings\", \"affection\", \"desire\",\n",
    "    \"argue\", \"fight\", \"breakup\", \"leave\", \"stay\", \"trust\",\n",
    "    \"sex\", \"freak\", \"body\", \"titties\", \"thot\", \"thots\", \"ass\"\n",
    "],\n",
    "}\n",
    "\n",
    "THEME_SETS = {name: set(words) for name, words in THEMES.items()}\n",
    "\n",
    "def theme_count(tokens, keyword_set):\n",
    "    \"\"\"Count how many tokens in this song belong to a theme.\"\"\"\n",
    "    return sum(1 for t in tokens if t in keyword_set)\n",
    "\n",
    "def add_theme_counts(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    for theme_name, keyword_set in THEME_SETS.items():\n",
    "        col_name = f\"{theme_name}_count\"\n",
    "        df[col_name] = df[\"tokens\"].apply(\n",
    "            lambda tokens: theme_count(tokens, keyword_set)\n",
    "        )\n",
    "    return df\n",
    "\n",
    "# Recompute counts\n",
    "df = add_theme_counts(df)\n",
    "\n",
    "# Quick view of the 3 theme columns (first 10 songs)\n",
    "df[[c for c in df.columns if c.endswith(\"_count\")]].head(10)\n",
    "\n",
    "# --- TOTAL COUNTS ACROSS THE ENTIRE CORPUS ---\n",
    "theme_cols = [\"wealth_count\", \"religion_count\", \"relationships_count\"]\n",
    "\n",
    "print(\"=== TOTAL THEME COUNTS ACROSS ALL SONGS ===\")\n",
    "total_theme_counts = df[theme_cols].sum()\n",
    "print(total_theme_counts)\n",
    "\n",
    "\n",
    "summary_df = pd.DataFrame({\n",
    "    \"Theme\": [\"Wealth\", \"Religion\", \"Relationships\"],\n",
    "    \"Total Keyword Count\": [\n",
    "        total_theme_counts[\"wealth_count\"],\n",
    "        total_theme_counts[\"religion_count\"],\n",
    "        total_theme_counts[\"relationships_count\"]\n",
    "    ]\n",
    "})\n",
    "\n",
    "summary_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4174bfa",
   "metadata": {},
   "source": [
    "\n",
    "## 9. Word Co-occurrence Network (Network Analysis)\n",
    "\n",
    "To tackle the **network analysis** component, I built a graph where:\n",
    "\n",
    "- Nodes = words  \n",
    "- Edges = words that appear together in the same song  \n",
    "- Edge weight = how many songs the word pair co-occurs in  \n",
    "\n",
    "I applied a threshold to filter out weak connections so the network is more interpretable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba5941c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 9.1 Ensure we have tokens for each lyric block\n",
    "if \"tokens\" not in df.columns:\n",
    "    df[\"tokens\"] = df[\"lyrics\"].apply(clean_text)\n",
    "\n",
    "# 9.2 Count tokens and filter to reasonably frequent words\n",
    "token_counts = Counter(t for tokens in df[\"tokens\"] for t in tokens)\n",
    "\n",
    "MIN_WORD_FREQ = 30   # ignore very rare words\n",
    "vocab = {w for w, c in token_counts.items() if c >= MIN_WORD_FREQ}\n",
    "\n",
    "# 9.3 Build co-occurrence pairs\n",
    "cooc = Counter()\n",
    "for tokens in df[\"tokens\"]:\n",
    "    words = sorted(set(t for t in tokens if t in vocab))\n",
    "    for w1, w2 in itertools.combinations(words, 2):\n",
    "        cooc[(w1, w2)] += 1\n",
    "\n",
    "# 9.4 Build weighted graph from co-occurrence counts\n",
    "G = nx.Graph()\n",
    "MIN_COOCCUR = 5      # only keep edges for pairs seen together at least this many times\n",
    "\n",
    "for (w1, w2), w in cooc.items():\n",
    "    if w >= MIN_COOCCUR:\n",
    "        G.add_edge(w1, w2, weight=w)\n",
    "\n",
    "# 9.5 Focus on the top-N most connected words for readability\n",
    "TOP_N = 35\n",
    "deg_full = dict(G.degree())\n",
    "top_nodes = [n for n, _ in sorted(deg_full.items(),\n",
    "                                  key=lambda x: x[1],\n",
    "                                  reverse=True)[:TOP_N]]\n",
    "\n",
    "H = G.subgraph(top_nodes).copy()\n",
    "degrees = dict(H.degree())\n",
    "\n",
    "print(\"Nodes plotted:\", len(H.nodes()))\n",
    "print(\"Edges plotted:\", len(H.edges()))\n",
    "\n",
    "# 9.6 Layout for visualization\n",
    "pos = nx.spring_layout(H, k=0.45, iterations=150, seed=42)\n",
    "\n",
    "## Theme-Colored Co-occurrence Network (Wealth / Religion / Relationships)\n",
    "\n",
    "# Turn theme lists into sets for quick lookup (assumes THEMES is defined above)\n",
    "wealth_words = set(THEMES.get(\"wealth\", []))\n",
    "religion_words = set(THEMES.get(\"religion\", []))\n",
    "rel_words = set(THEMES.get(\"relationships\", []))\n",
    "\n",
    "def node_color(word):\n",
    "    if word in rel_words:\n",
    "        return \"#e74c3c\"   # red: relationships\n",
    "    elif word in religion_words:\n",
    "        return \"#8e44ad\"   # purple: religion\n",
    "    elif word in wealth_words:\n",
    "        return \"#f1c40f\"   # gold: wealth\n",
    "    else:\n",
    "        return \"#3498db\"   # blue: other\n",
    "\n",
    "node_colors = [node_color(n) for n in H.nodes()]\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "node_sizes = [degrees[n] * 35 for n in H.nodes()]\n",
    "edge_widths = [H[u][v]['weight'] * 0.08 for u, v in H.edges()]\n",
    "\n",
    "nx.draw_networkx_edges(\n",
    "    H, pos,\n",
    "    width=edge_widths,\n",
    "    edge_color=\"lightgray\",\n",
    "    alpha=0.25\n",
    ")\n",
    "\n",
    "nx.draw_networkx_nodes(\n",
    "    H, pos,\n",
    "    node_size=node_sizes,\n",
    "    node_color=node_colors,\n",
    "    edgecolors=\"black\",\n",
    "    linewidths=0.5,\n",
    "    alpha=0.95\n",
    ")\n",
    "\n",
    "nx.draw_networkx_labels(H, pos, font_size=11)\n",
    "\n",
    "plt.title(\"Kanye West Lyrics – Co-occurrence Network by Theme\", fontsize=16)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06e68f1",
   "metadata": {},
   "source": [
    "\n",
    "## 10. Save Processed Data (Optional)\n",
    "\n",
    "Save the processed DataFrame (with tokens, sentiment scores, and theme counts) for later use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fde2d34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_pickle(\"kanye_lyrics_processed.pkl\")\n",
    "df.to_csv(\"kanye_lyrics_processed.csv\", index=False)\n",
    "print(\"Saved processed data to 'kanye_lyrics_processed.pkl' and 'kanye_lyrics_processed.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aedefad",
   "metadata": {},
   "source": [
    "\n",
    "## 11. Summary\n",
    "\n",
    "- Downloaded Kanye West's lyrics dataset from Kaggle\n",
    "- Cleaned and preprocessed the lyrics\n",
    "- Explored word frequencies\n",
    "- Performed sentiment analysis\n",
    "- Built and visualized a word co-occurrence network (network analysis)\n",
    "- Generated word clouds (overall and per album)\n",
    "- Quantified theme frequencies for **wealth**, **religion**, and **relationships**\n",
    "\n",
    "These results support the hypothesis that Kanye's lyrics contain recurring themes related to wealth, religion, and relationships, and that these themes appear consistently across his albums, with some variation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
