{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c94d3c1",
   "metadata": {},
   "source": [
    "\n",
    "# Repeat Themes in Kanye West’s Lyrics: Wealth, Religion, and Relationships\n",
    "\n",
    "This notebook implements the full analysis pipeline for your **Data 620 final project**, using the Kaggle dataset:\n",
    "\n",
    "> `convolutionalnn/kanye-west-lyrics-dataset`\n",
    "\n",
    "It includes:\n",
    "\n",
    "1. Data download and loading (via `kagglehub`)\n",
    "2. Text preprocessing (tokenization, stopword removal, lemmatization)\n",
    "3. Word frequency analysis\n",
    "4. Sentiment analysis (VADER)\n",
    "5. Word co-occurrence network (NetworkX)\n",
    "6. Topic modeling (LDA)\n",
    "7. Word clouds (overall and per album)\n",
    "8. Theme keyword analysis (wealth, religion, relationships)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff66c13",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Setup and Library Installation\n",
    "\n",
    "Run this cell **once** to install any missing libraries.  \n",
    "If you already have them installed, you can skip or comment out the `pip install` lines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc57941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If needed, uncomment these lines to install dependencies in your environment.\n",
    "\n",
    "# !pip install kagglehub\n",
    "# !pip install pandas matplotlib seaborn nltk networkx gensim wordcloud\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "import string\n",
    "import networkx as nx\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "# Make plots a bit nicer\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 5)\n",
    "\n",
    "# Download NLTK resources (safe to run multiple times)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('vader_lexicon', quiet=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76a80d3",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Download the Kanye West Lyrics Dataset (Kaggle)\n",
    "\n",
    "We will use `kagglehub` to automatically download the latest version of the dataset from Kaggle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b383e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Download latest version of the dataset from Kaggle\n",
    "dataset_dir = kagglehub.dataset_download(\"convolutionalnn/kanye-west-lyrics-dataset\")\n",
    "print(\"Dataset directory:\", dataset_dir)\n",
    "\n",
    "# Inspect files in the dataset directory\n",
    "files = os.listdir(dataset_dir)\n",
    "print(\"Files found in dataset directory:\", files)\n",
    "\n",
    "# Automatically pick the first .txt or .csv file\n",
    "data_file = None\n",
    "for f in files:\n",
    "    if f.lower().endswith(\".txt\") or f.lower().endswith(\".csv\"):\n",
    "        data_file = os.path.join(dataset_dir, f)\n",
    "        break\n",
    "\n",
    "if data_file is None:\n",
    "    raise FileNotFoundError(\"No .txt or .csv file found in the dataset directory. Check Kaggle dataset contents.\")\n",
    "\n",
    "print(\"Using data file:\", data_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e2d28c",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Load and Inspect the Dataset\n",
    "\n",
    "The dataset file may be in `.txt` or `.csv` format.  \n",
    "We try to read it as a regular CSV first, and if that fails, we try tab-separated text.\n",
    "\n",
    "We also normalize column names to lowercase and ensure that there is a `lyrics` column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761b4e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_dataset(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Load the Kanye West lyrics dataset from a text/CSV file.\n",
    "\n",
    "    - Tries standard CSV reading first.\n",
    "    - If that fails, tries tab-separated format.\n",
    "    - Normalizes column names to lowercase.\n",
    "    - Ensures there is a 'lyrics' column (renaming common alternatives if needed).\n",
    "    \"\"\"\n",
    "    print(\"Loading dataset from:\", file_path)\n",
    "    \n",
    "    # Try reading as standard CSV\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "    except Exception as e:\n",
    "        print(\"Standard CSV read failed:\", e)\n",
    "        print(\"Trying tab-separated format (sep='\\t')...\")\n",
    "        df = pd.read_csv(file_path, sep=\"\\t\", engine=\"python\")\n",
    "    \n",
    "    print(\"Initial shape:\", df.shape)\n",
    "    print(\"Original columns:\", df.columns.tolist())\n",
    "    \n",
    "    # Normalize column names to lowercase\n",
    "    df.columns = [col.lower() for col in df.columns]\n",
    "    print(\"Normalized columns:\", df.columns.tolist())\n",
    "    \n",
    "    # Try to ensure there is a 'lyrics' column\n",
    "    if \"lyrics\" not in df.columns:\n",
    "        for alt in [\"lyric\", \"text\", \"content\"]:\n",
    "            if alt in df.columns:\n",
    "                df.rename(columns={alt: \"lyrics\"}, inplace=True)\n",
    "                break\n",
    "    \n",
    "    if \"lyrics\" not in df.columns:\n",
    "        raise KeyError(\"Could not find a 'lyrics' column. Please check the dataset structure.\")\n",
    "    \n",
    "    # Optional: standardize 'album' column name if needed\n",
    "    if \"album\" not in df.columns:\n",
    "        for alt in [\"albums\", \"record\", \"release\"]:\n",
    "            if alt in df.columns:\n",
    "                df.rename(columns={alt: \"album\"}, inplace=True)\n",
    "                break\n",
    "    \n",
    "    # Drop rows with missing lyrics and remove duplicates\n",
    "    df = df.dropna(subset=[\"lyrics\"])\n",
    "    df = df.drop_duplicates(subset=[\"lyrics\"])\n",
    "    \n",
    "    print(\"Shape after cleaning lyrics:\", df.shape)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "df = load_dataset(data_file)\n",
    "\n",
    "# Quick peek\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070eacbb",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Text Preprocessing: Tokenization, Stopwords, Lemmatization\n",
    "\n",
    "To prepare the lyrics for analysis, we:\n",
    "\n",
    "- Convert text to lowercase  \n",
    "- Remove punctuation  \n",
    "- Tokenize into words  \n",
    "- Remove English stopwords (e.g., 'the', 'and')  \n",
    "- Lemmatize words to their base form (e.g., 'running' → 'run')  \n",
    "\n",
    "This results in a normalized `tokens` column we can use for all downstream analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e519a629",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def clean_text(text: str):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords and very short tokens\n",
    "    tokens = [t for t in tokens if t not in stop_words and len(t) > 2]\n",
    "    # Lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
    "    return tokens\n",
    "\n",
    "# Apply to the lyrics column\n",
    "df[\"tokens\"] = df[\"lyrics\"].apply(clean_text)\n",
    "\n",
    "# Show a few examples\n",
    "df[[\"lyrics\", \"tokens\"]].head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43b40a5",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Word Frequency Analysis\n",
    "\n",
    "As a first exploratory step, we examine the most frequently used words across Kanye's lyrics.\n",
    "\n",
    "This helps us see which concepts are dominant in his vocabulary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064fa94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import Counter\n",
    "\n",
    "def analyze_word_frequencies(df: pd.DataFrame, top_n: int = 30):\n",
    "    all_tokens = [token for sublist in df[\"tokens\"] for token in sublist]\n",
    "    freq = Counter(all_tokens)\n",
    "    common = freq.most_common(top_n)\n",
    "    \n",
    "    print(f\"Top {top_n} most common words:\")\n",
    "    for word, count in common:\n",
    "        print(f\"{word}: {count}\")\n",
    "    \n",
    "    words, counts = zip(*common)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=list(counts), y=list(words))\n",
    "    plt.title(f\"Top {top_n} Words in Kanye West Lyrics\")\n",
    "    plt.xlabel(\"Count\")\n",
    "    plt.ylabel(\"Word\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "analyze_word_frequencies(df, top_n=30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ad1b4e",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Sentiment Analysis (VADER)\n",
    "\n",
    "We use NLTK's VADER sentiment analyzer to measure:\n",
    "\n",
    "- Negative (`neg`)  \n",
    "- Neutral (`neu`)  \n",
    "- Positive (`pos`)  \n",
    "- Overall compound score (`compound`)  \n",
    "\n",
    "for each lyrics entry. This gives us a sense of the emotional tone of Kanye's songs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a70122",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_sentiment_analysis(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    sentiment_dicts = df[\"lyrics\"].apply(sia.polarity_scores)\n",
    "    sentiment_df = pd.json_normalize(sentiment_dicts)\n",
    "    df_sent = pd.concat([df.reset_index(drop=True), sentiment_df], axis=1)\n",
    "    \n",
    "    print(\"Example sentiment scores:\")\n",
    "    display(df_sent[[\"lyrics\", \"neg\", \"neu\", \"pos\", \"compound\"]].head(3))\n",
    "    \n",
    "    # Plot distribution of compound scores\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.histplot(df_sent[\"compound\"], bins=50, kde=True)\n",
    "    plt.title(\"Distribution of Compound Sentiment Scores\")\n",
    "    plt.xlabel(\"Compound Score\")\n",
    "    plt.ylabel(\"Number of Songs\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # If album info exists, show sentiment by album\n",
    "    if \"album\" in df_sent.columns:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.boxplot(data=df_sent, x=\"album\", y=\"compound\")\n",
    "        plt.xticks(rotation=45, ha=\"right\")\n",
    "        plt.title(\"Sentiment (Compound) by Album\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return df_sent\n",
    "\n",
    "df = run_sentiment_analysis(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4174bfa",
   "metadata": {},
   "source": [
    "\n",
    "## 7. Word Co-occurrence Network (Network Analysis)\n",
    "\n",
    "To satisfy the **network analysis** component, we build a graph where:\n",
    "\n",
    "- Nodes = words  \n",
    "- Edges = words that appear together in the same song  \n",
    "- Edge weight = how many songs the word pair co-occurs in  \n",
    "\n",
    "We apply a threshold to filter out weak connections so the network is more interpretable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba5941c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from itertools import combinations\n",
    "\n",
    "COOCCURRENCE_THRESHOLD = 8  # adjust if too dense or too sparse\n",
    "\n",
    "def build_cooccurrence_network(df: pd.DataFrame, threshold: int = COOCCURRENCE_THRESHOLD) -> nx.Graph:\n",
    "    cooccurrence = Counter()\n",
    "    \n",
    "    for tokens in df[\"tokens\"]:\n",
    "        unique_tokens = set(tokens)\n",
    "        for pair in combinations(unique_tokens, 2):\n",
    "            cooccurrence[pair] += 1\n",
    "    \n",
    "    G = nx.Graph()\n",
    "    for (w1, w2), weight in cooccurrence.items():\n",
    "        if weight >= threshold:\n",
    "            G.add_edge(w1, w2, weight=weight)\n",
    "    \n",
    "    print(\"Number of nodes:\", G.number_of_nodes())\n",
    "    print(\"Number of edges:\", G.number_of_edges())\n",
    "    return G\n",
    "\n",
    "def visualize_cooccurrence_network(G: nx.Graph):\n",
    "    if G.number_of_nodes() == 0:\n",
    "        print(\"Graph is empty; nothing to visualize.\")\n",
    "        return\n",
    "    \n",
    "    plt.figure(figsize=(14, 12))\n",
    "    pos = nx.spring_layout(G, k=0.55, seed=42)\n",
    "    weights = [G[u][v][\"weight\"] for u, v in G.edges()]\n",
    "    \n",
    "    nx.draw_networkx_nodes(G, pos, node_size=60, node_color=\"red\", alpha=0.8)\n",
    "    nx.draw_networkx_edges(G, pos, width=np.array(weights) / 2.0, alpha=0.4)\n",
    "    nx.draw_networkx_labels(G, pos, font_size=8)\n",
    "    \n",
    "    plt.title(\"Kanye West Lyrics – Word Co-occurrence Network\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "G = build_cooccurrence_network(df, threshold=COOCCURRENCE_THRESHOLD)\n",
    "visualize_cooccurrence_network(G)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2cbdd2",
   "metadata": {},
   "source": [
    "\n",
    "## 8. Topic Modeling with LDA\n",
    "\n",
    "We apply Latent Dirichlet Allocation (LDA) to discover **latent topics** in the lyrics.\n",
    "\n",
    "This helps us see whether themes like **wealth**, **religion**, and **relationships** emerge naturally from the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bd1518",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NUM_TOPICS = 5\n",
    "\n",
    "def run_lda_topic_modeling(df: pd.DataFrame, num_topics: int = NUM_TOPICS):\n",
    "    dictionary = corpora.Dictionary(df[\"tokens\"])\n",
    "    corpus = [dictionary.doc2bow(tokens) for tokens in df[\"tokens\"]]\n",
    "    \n",
    "    lda_model = LdaModel(\n",
    "        corpus=corpus,\n",
    "        id2word=dictionary,\n",
    "        num_topics=num_topics,\n",
    "        passes=10,\n",
    "        random_state=42,\n",
    "    )\n",
    "    \n",
    "    print(\"Topics discovered by LDA:\\n\")\n",
    "    for i, topic in lda_model.print_topics():\n",
    "        print(f\"Topic {i}: {topic}\\n\")\n",
    "    \n",
    "    return lda_model, corpus, dictionary\n",
    "\n",
    "lda_model, corpus, dictionary = run_lda_topic_modeling(df, num_topics=NUM_TOPICS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90551d67",
   "metadata": {},
   "source": [
    "\n",
    "## 9. Word Clouds (Overall and Per Album)\n",
    "\n",
    "Word clouds provide an intuitive visual summary of the most frequent words.\n",
    "\n",
    "- The **global** word cloud shows overall vocabulary.  \n",
    "- **Per-album** word clouds highlight how themes shift across Kanye's discography.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4766c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_global_wordcloud(df: pd.DataFrame):\n",
    "    all_text = \" \".join(df[\"lyrics\"].tolist())\n",
    "    wc = WordCloud(width=1200, height=800, background_color=\"white\").generate(all_text)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Kanye West Lyrics – Global WordCloud\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def generate_wordclouds_by_album(df: pd.DataFrame):\n",
    "    if \"album\" not in df.columns:\n",
    "        print(\"No 'album' column found; skipping per-album word clouds.\")\n",
    "        return\n",
    "    \n",
    "    for album in df[\"album\"].dropna().unique():\n",
    "        subset = df[df[\"album\"] == album]\n",
    "        text = \" \".join(subset[\"lyrics\"].tolist())\n",
    "        if not text.strip():\n",
    "            continue\n",
    "        \n",
    "        wc = WordCloud(width=1000, height=600, background_color=\"black\").generate(text)\n",
    "        \n",
    "        plt.figure(figsize=(12, 7))\n",
    "        plt.imshow(wc, interpolation=\"bilinear\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"WordCloud – {album}\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "generate_global_wordcloud(df)\n",
    "generate_wordclouds_by_album(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34e151d",
   "metadata": {},
   "source": [
    "\n",
    "## 10. Theme Keyword Analysis: Wealth, Religion, Relationships\n",
    "\n",
    "To directly test the hypothesis, we:\n",
    "\n",
    "1. Define keyword lists for each theme.  \n",
    "2. Count how many times theme-related words appear in each song.  \n",
    "3. Aggregate counts by album to see which albums emphasize which themes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351f0218",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "THEMES = {\n",
    "    \"wealth\": [\"money\", \"cash\", \"gold\", \"rich\", \"bank\", \"chain\", \"ballin\", \"bread\", \"dollars\"],\n",
    "    \"religion\": [\"god\", \"pray\", \"church\", \"heaven\", \"faith\", \"jesus\", \"bible\", \"saint\"],\n",
    "    \"relationships\": [\"love\", \"heart\", \"baby\", \"girl\", \"boy\", \"relationship\", \"wife\", \"husband\"],\n",
    "}\n",
    "\n",
    "def theme_count(tokens, keywords):\n",
    "    return sum(1 for t in tokens if t in keywords)\n",
    "\n",
    "def add_theme_counts(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    for theme_name, keywords in THEMES.items():\n",
    "        col_name = f\"{theme_name}_count\"\n",
    "        df[col_name] = df[\"tokens\"].apply(lambda tokens: theme_count(tokens, keywords))\n",
    "    return df\n",
    "\n",
    "df = add_theme_counts(df)\n",
    "\n",
    "df[[col for col in df.columns if col.endswith(\"_count\")]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00df578f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_theme_trends_by_album(df: pd.DataFrame):\n",
    "    if \"album\" not in df.columns:\n",
    "        print(\"No 'album' column found; skipping theme trends by album.\")\n",
    "        return\n",
    "    \n",
    "    theme_cols = [f\"{t}_count\" for t in THEMES.keys()]\n",
    "    theme_summary = df.groupby(\"album\")[theme_cols].sum()\n",
    "    \n",
    "    print(\"Theme counts by album:\")\n",
    "    display(theme_summary)\n",
    "    \n",
    "    theme_summary.plot(kind=\"bar\", figsize=(12, 6))\n",
    "    plt.title(\"Theme Frequency by Album (Wealth, Religion, Relationships)\")\n",
    "    plt.xlabel(\"Album\")\n",
    "    plt.ylabel(\"Keyword Count\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_theme_trends_by_album(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06e68f1",
   "metadata": {},
   "source": [
    "\n",
    "## 11. Save Processed Data (Optional)\n",
    "\n",
    "We can save the processed DataFrame (with tokens, sentiment scores, and theme counts) for later use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fde2d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.to_pickle(\"kanye_lyrics_processed.pkl\")\n",
    "df.to_csv(\"kanye_lyrics_processed.csv\", index=False)\n",
    "print(\"Saved processed data to 'kanye_lyrics_processed.pkl' and 'kanye_lyrics_processed.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aedefad",
   "metadata": {},
   "source": [
    "\n",
    "## 12. Summary\n",
    "\n",
    "In this notebook, we:\n",
    "\n",
    "- Downloaded Kanye West's lyrics dataset from Kaggle\n",
    "- Cleaned and preprocessed the lyrics\n",
    "- Explored word frequencies\n",
    "- Performed sentiment analysis\n",
    "- Built and visualized a word co-occurrence network (network analysis)\n",
    "- Applied LDA topic modeling\n",
    "- Generated word clouds (overall and per album)\n",
    "- Quantified theme frequencies for **wealth**, **religion**, and **relationships**\n",
    "\n",
    "These results support the hypothesis that Kanye's lyrics contain recurring themes related to wealth, religion, and relationships, and that these themes appear consistently across his albums, with some variation.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
